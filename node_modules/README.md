# Anna's Archive Scraper üìö

A powerful Node.js tool for searching and downloading books from Anna's Archive. Built with Puppeteer for reliable web scraping with Cloudflare bypass capabilities.

## Features

- üîç **Smart Search**: Search by book title, author, ISBN, or any keyword
- üì• **Direct Downloads**: Get direct download links for books
- üõ°Ô∏è **Cloudflare Bypass**: Automatic handling of Cloudflare protection
- üîÑ **Retry Mechanism**: Configurable retry attempts for failed downloads
- üì± **Multiple Formats**: Supports PDF, EPUB, DJVU, FB2, MOBI formats
- üéØ **CLI & Module**: Use as command-line tool or import as module
- ‚ö° **Efficient**: Removes duplicates and optimizes requests

## Installation

### Prerequisites
- Node.js 14.0.0 or higher
- npm or yarn

### Install dependencies
```bash
npm install
```

### Global Installation (Optional)
```bash
npm install -g
```

## Usage

### Command Line Interface

#### Search for books
```bash
# Search by title
node scraper.js "The Great Gatsby"

# Search by author
node scraper.js "George Orwell"

# Search with multiple terms
node scraper.js "Harry Potter Philosopher Stone"
```

#### Direct hash lookup
```bash
# Use MD5 hash directly
node scraper.js --hash a1b2c3d4e5f6789...
```

#### Help
```bash
node scraper.js --help
```

### As Node.js Module

```javascript
const AnnasArchiveScraper = require('./scraper');

async function example() {
  // Initialize scraper with options
  const scraper = new AnnasArchiveScraper({
    headless: true,        // Run in headless mode
    timeout: 30000,        // Request timeout
    retryAttempts: 3,      // Number of retry attempts
    waitTime: 8000         // Initial wait time
  });

  try {
    // Search for books
    const books = await scraper.searchBooks('1984 George Orwell');
    console.log('Found books:', books);

    // Get download link for first result
    if (books.length > 0) {
      const downloadUrl = await scraper.getDownloadLink(books[0].md5);
      console.log('Download URL:', downloadUrl);
    }

    // Or use the all-in-one method
    const directUrl = await scraper.downloadBook('The Hobbit');
    console.log('Direct download:', directUrl);

  } catch (error) {
    console.error('Error:', error.message);
  }
}

example();
```

## API Reference

### Class: AnnasArchiveScraper

#### Constructor
```javascript
new AnnasArchiveScraper(options)
```

**Options:**
- `headless` (boolean): Run browser in headless mode (default: true)
- `timeout` (number): Request timeout in milliseconds (default: 30000)
- `retryAttempts` (number): Number of retry attempts (default: 3)
- `waitTime` (number): Initial wait time in milliseconds (default: 8000)

#### Methods

##### searchBooks(query)
Search for books on Anna's Archive.
- **query** (string): Search term (title, author, ISBN, etc.)
- **Returns:** Promise<Array> - Array of book objects

```javascript
const books = await scraper.searchBooks('JavaScript Guide');
// Returns: [{ title: '...', md5: '...', url: '...' }, ...]
```

##### getDownloadLink(md5Hash)
Get download link for a specific book.
- **md5Hash** (string): MD5 hash of the book
- **Returns:** Promise<string|null> - Download URL or null

```javascript
const url = await scraper.getDownloadLink('a1b2c3d4...');
```

##### downloadBook(query, isHash)
Search and download with retry mechanism.
- **query** (string): Search query or MD5 hash
- **isHash** (boolean): Whether query is an MD5 hash (default: false)
- **Returns:** Promise<string|null> - Download URL or null

```javascript
const url = await scraper.downloadBook('Python Crash Course');
```

## Configuration

### Environment Variables
```bash
# Optional: Set custom Chrome path
CHROME_PATH=/path/to/chrome

# Optional: Set custom user data directory
CHROME_USER_DATA=/path/to/userdata
```

### Advanced Options
```javascript
const scraper = new AnnasArchiveScraper({
  headless: false,           // Show browser window
  timeout: 60000,            // 60 second timeout
  retryAttempts: 5,          // Try 5 times
  waitTime: 10000,           // Wait 10 seconds initially
});
```

## Error Handling

The scraper includes comprehensive error handling:

```javascript
try {
  const result = await scraper.downloadBook('Book Title');
  if (result) {
    console.log('Success:', result);
  } else {
    console.log('No download link found');
  }
} catch (error) {
  console.error('Error occurred:', error.message);
}
```

## Troubleshooting

### Common Issues

#### Cloudflare Challenges
- The scraper automatically handles Cloudflare protection
- If issues persist, try increasing `waitTime` option

#### No Results Found
- Check spelling of search terms
- Try different search keywords
- Some books might not be available

#### Timeout Errors
- Increase the `timeout` option
- Check your internet connection
- Some regions might have slower access

#### Browser Issues
- Ensure you have Chrome/Chromium installed
- Try running with `headless: false` to see browser actions
- Check if you have sufficient disk space for browser cache

### Debug Mode
Run with visible browser for debugging:
```javascript
const scraper = new AnnasArchiveScraper({ headless: false });
```

## Legal Disclaimer

This tool is for educational purposes only. Users are responsible for complying with their local laws and the terms of service of Anna's Archive. The authors do not encourage or condone copyright infringement.

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Changelog

### v1.0.0
- Initial release
- Basic search and download functionality
- Cloudflare bypass
- CLI interface
- Module support

## Support

If you encounter any issues or have questions:

1. Check the [Issues](https://github.com/yourusername/annas-archive-scraper/issues) page
2. Create a new issue with detailed description
3. Include error messages and system information

---

‚≠ê **Star this repository if it helped you!**